{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2779e951-7907-4063-964c-6a298f969d0b",
   "metadata": {},
   "source": [
    "# day04Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4311863-25fe-447d-a41a-6a93a43b1b72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## day04上课内容"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc714c75-9c86-40aa-9b76-381692b9aa4a",
   "metadata": {},
   "source": [
    "内容小标题:\n",
    "    1、Prompt定义\n",
    "    2、Prompt Engineering\n",
    "    3、如何正确理解Engineering工程化\n",
    "    4、Prompt的典型构成要素\n",
    "    5、设置Prompt的通用技巧\n",
    "    6、Zero-shot\n",
    "    7、Few-shot\n",
    "    8、Chain-of-Thought Prompting(COT)\n",
    "通过本节课你能够学到什么?\n",
    "    1、正式进入到提示工程的学习\n",
    "    2、逐渐了解提示工程的生态\n",
    "    3、进入提示工程的工程化实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009671c3-8650-4d74-ba74-16037cca7ea2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 什么是提示词(Propmt)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c8030e6-0106-4d0b-a725-f9f658d88a3c",
   "metadata": {},
   "source": [
    "    所谓的提示词其实指的就是提供给模型的一个文本片段，用于指导模型生成特定的输出或回答。提示词的目的是为模型提供一个任务的上下文，以便模型能够更准确地理解用户的意图，并生成相关的回应。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c93b08-932c-4905-8f98-655653dabcaa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 什么是提示工程(Prompt Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709d20a-2cde-486b-9f53-ab4099e5d396",
   "metadata": {},
   "source": [
    "所谓的提示工程也可以被称为「指令工程」，\n",
    "提示工程的核心思想是，通过精心设计的提示，可以显著提高模型的性能和输出质量。\n",
    "+ 貌似简单，但其实意义非凡。（提问的智慧）\n",
    "    + Prompt 是 AGI 时代的「编程语言」\n",
    "    + 提示工程师是 AGI 时代的「程序员」\n",
    "\n",
    "如果要学好提示工程，那么其实就是要知道如何对咱们的Prompt进行调优，与大模型进行更好的交互。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db1c6b-55ab-45af-84f7-e791a55fd8de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 如何正确理解Engineering工程化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1c050-6700-4aff-b81d-d3baa2b62d61",
   "metadata": {},
   "source": [
    "<img src=\"./img/大模型重要四阶段.jpg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ce49e-5ce5-4f4f-8587-a785af39ba80",
   "metadata": {},
   "source": [
    "<img src=\"./img/what is prompt engineering.jpg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c66bcc-6e69-4a5e-9ca9-a7faa233e90e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prompt的典型构成要素"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a41b4f64-ad2c-47c2-8afd-b267589819ba",
   "metadata": {},
   "source": [
    "举个例子：\n",
    "    「输出一个九九乘法口诀表」\n",
    "    「请使用python语言 只能利用for循环不能使用其他的语法 输出一个九九乘法口诀表并写好相应的注释」\n",
    "大家可以使用以上两个Propmt实例，分别体验一下gpt给我们的回答。\n",
    "\n",
    "如果说想要设置一个高质量的prompt\n",
    "简而言之：\n",
    "    具体、丰富、少歧义\n",
    "延伸: 对于咱们生活中的短句 聊天记录 都不是好的Prompt 而国外在进行信息同步时 多采用邮箱的形式 格式统一是比较好的Propmt\n",
    "\n",
    "对于一个高质量的Propmt 我们应该具有以下要素:\n",
    "    指令：想要模型执行的特定任务或指令。\n",
    "    上下文：包含外部信息或额外的上下文信息，引导语言模型更好地响应。\n",
    "    输入数据：用户输入的内容或问题。\n",
    "    输出指示：指定输出的类型或格式。\n",
    "\n",
    "注意点: 并不是说我们构建一个Propmpt一定需要这四个要素！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5531d-13e7-447d-b3a1-295648f967f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 设置Prompt的通用技巧"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80c89e7d-5052-4b2c-b884-62a88d62c81e",
   "metadata": {},
   "source": [
    "1、具体性\n",
    "2、示例和格式\n",
    "3、避免不精确\n",
    "4、做还是不做？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d9dde6-ef02-4c48-8a9c-c628690c5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c613239a-d568-4ab5-a9a8-c6d53ff740c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1、具体性\"\"\"\n",
    "prompt = '输出一个九九乘法口诀表'\n",
    "# prompt = '请使用python语言 只能利用for循环不能使用其他的语法 输出一个九九乘法口诀表并写好相应的注释'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e19b9d99-353a-4917-b7ee-11bf589c43cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！以下是九九乘法口诀表：\n",
      "\n",
      "```\n",
      "1 x 1 = 1\n",
      "1 x 2 = 2    2 x 2 = 4\n",
      "1 x 3 = 3    2 x 3 = 6    3 x 3 = 9\n",
      "1 x 4 = 4    2 x 4 = 8    3 x 4 = 12   4 x 4 = 16\n",
      "1 x 5 = 5    2 x 5 = 10   3 x 5 = 15   4 x 5 = 20   5 x 5 = 25\n",
      "1 x 6 = 6    2 x 6 = 12   3 x 6 = 18   4 x 6 = 24   5 x 6 = 30   6 x 6 = 36\n",
      "1 x 7 = 7    2 x 7 = 14   3 x 7 = 21   4 x 7 = 28   5 x 7 = 35   6 x 7 = 42   7 x 7 = 49\n",
      "1 x 8 = 8    2 x 8 = 16   3 x 8 = 24   4 x 8 = 32   5 x 8 = 40   6 x 8 = 48   7 x 8 = 56   8 x 8 = 64\n",
      "1 x 9 = 9    2 x 9 = 18   3 x 9 = 27   4 x 9 = 36   5 x 9 = 45   6 x 9 = 54   7 x 9 = 63   8 x 9 = 72   9 x 9 = 81\n",
      "```\n",
      "\n",
      "这是一个完整的九九乘法口诀表，方便你进行乘法运算的参考！\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature = 0,  # 模型输出的随机性，0表示随机性最小\n",
    "    )\n",
    "    # print(response)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb7917e2-acb6-49e7-b4df-30573bb8c290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "你的任务是识别用户输入的的信息\n",
      "提取出对应的时间(time),地点(Locations)、人物(character)\n",
      "\n",
      "\n",
      "\n",
      "并以JSON格式输出\n",
      "\n",
      "\n",
      "\n",
      "在本周末，我将和我的同事王五一起去海洋公园玩耍。{\"时间\": \"本周末\",\"地点\": \"海洋公园\",\"人物\": [\"我\", \"我的同事王五\"]}\n",
      "\n",
      "\n",
      "用户输入：\n",
      "今天晚上，王思聪叫我去酒吧喝酒，他说有八个妹妹，李易峰和吴亦凡都去，哈哈哈\n",
      "\n",
      "{\n",
      "  \"时间\": \"今天晚上\",\n",
      "  \"地点\": \"酒吧\",\n",
      "  \"人物\": [\"王思聪\", \"我\", \"李易峰\", \"吴亦凡\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"2、示例与格式\"\"\"\n",
    "instruction = \"\"\"\n",
    "你的任务是识别用户输入的的信息\n",
    "提取出对应的时间(time),地点(Locations)、人物(character)\n",
    "\"\"\"\n",
    "output = \"\"\"\n",
    "并以JSON格式输出\n",
    "\"\"\"\n",
    "# input_text = \"\"\"去年愚人节，我的死党胖虎在公司年会上cosplay成了唐僧，结果被一群“妖精”围追堵截，场面一度失控。\"\"\"\n",
    "input_text = \"\"\"今天晚上，王思聪叫我去酒吧喝酒，他说有八个妹妹，李易峰和吴亦凡都去，哈哈哈\"\"\"\n",
    "\n",
    "examples = \"\"\"\n",
    "在本周末，我将和我的同事王五一起去海洋公园玩耍。{\"时间\": \"本周末\",\"地点\": \"海洋公园\",\"人物\": [\"我\", \"我的同事王五\"]}\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "{instruction}\n",
    "\n",
    "{output}\n",
    "\n",
    "{examples}\n",
    "\n",
    "用户输入：\n",
    "{input_text}\n",
    "\"\"\"\n",
    "print(prompt)\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7596318-ee5b-46f9-88d1-3b91b5b94c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示工程是指通过设计和调整问题或指令的方式，来帮助计算机更好地理解和回答我们的请求。就像给朋友发信息时，我们要用清楚的话语，让他们明白我们想要什么。\n"
     ]
    }
   ],
   "source": [
    "\"\"\"3、避免不精确\"\"\"\n",
    "\n",
    "prompt1 = \"\"\"\n",
    "解释提示工程的概念。\n",
    "\"\"\"\n",
    "prompt2 = \"\"\"\n",
    "解释提示工程的概念。保持解释简短，只要几句话，不要过多描述。\n",
    "\"\"\"\n",
    "# 不清楚要使用多少句话和什么样的风格。\n",
    "# 您可能仍然可以通过上面的提示获得良好的响应，但更好的提示是非常具体、简洁和直接的。\n",
    "prompt3 = \"\"\"使用 2-3 句话解释提示工程的概念。我是小学生\"\"\"\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "print(get_completion(prompt3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d360d01-e72e-477c-9cb4-2db5a3307b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！以下是三个具体的行为措施，帮助你提高工作效率：\n",
      "\n",
      "1. **应该做的：设定优先级并使用待办事项清单。**\n",
      "   - 每天早晨花几分钟时间列出当天的任务，并根据重要性和紧急性进行排序。\n",
      "   - **不应该做的：随意处理任务，忽视优先级。**\n",
      "   - 避免在没有计划的情况下开始工作，这样容易导致时间浪费和效率低下。\n",
      "\n",
      "2. **应该做的：设定专注时间段，使用番茄工作法。**\n",
      "   - 每次专注工作25分钟，然后休息5分钟，完成四个番茄钟后再长休息15-30分钟。\n",
      "   - **不应该做的：在工作期间频繁中断自己。**\n",
      "   - 避免在专注时间内查看手机、回复邮件或进行其他干扰性活动。\n",
      "\n",
      "3. **应该做的：定期进行自我反思和总结。**\n",
      "   - 每周花时间回顾自己的工作进展，分析哪些方法有效，哪些需要改进。\n",
      "   - **不应该做的：忽视工作中的问题和挑战。**\n",
      "   - 避免在工作中遇到困难时不进行反思，而是要主动寻找解决方案和改进措施。 \n",
      "\n",
      "通过实施这些措施，你可以更有效地管理时间和任务，从而提高工作效率。\n"
     ]
    }
   ],
   "source": [
    "\"\"\"做还是不做\"\"\"\n",
    "\n",
    "prompt1 = \"\"\"\n",
    "你能告诉我如何提高工作效率吗？\n",
    "\"\"\"\n",
    "prompt2 = \"\"\"\n",
    "“请告诉我三个具体的行为措施，我可以采取这些措施来提高工作效率。\n",
    "请确保每个措施都是可行的日常行动，并且明确指出哪些行为是应该做的，哪些是应该避免的。\n",
    "例如，‘应该做的：每天早晨规划当天的工作任务；\n",
    "不应该做的：在工作时间频繁检查社交媒体。’”\n",
    "\"\"\"\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "print(get_completion(prompt2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3de7e-ecbb-46ac-a98b-4eb0905c2fa6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Zero-shot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe1862e8-9514-4bff-b787-1411245c9b6c",
   "metadata": {},
   "source": [
    "如今，经过大量数据训练并调整指令的LLM能够执行零样本任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d627d1a6-4113-47fa-ba94-c8ec93185928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中性。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "将文本分类为中性、负面或正面。\n",
    "文本：我认为这家餐馆的菜品一般。\n",
    "情感：\n",
    "\"\"\"\n",
    "# 在上面的提示中，我们没有向模型提供任何示例——这就是零样本能力的作用。\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "\n",
    "        \n",
    "        messages=messages,\n",
    "        temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a018c-2541-4dab-9e66-66a456873b9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Few-shot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bee88c5-d330-4a5a-904e-fa064d4d3f59",
   "metadata": {},
   "source": [
    "    虽然大型语言模型展示了惊人的零样本能力，但在使用零样本设置时，它们在更复杂的任务上仍然表现不佳。少样本提示可以作为一种技术，以启用上下文学习，我们在提示中提供演示以引导模型实现更好的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f97bca7-9693-4b55-a844-11ff7e763018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. generate text\n",
      "2. language translation\n",
      "3. question answering\n",
      "4. conversation system\n",
      "5. summary generation\n",
      "6. text classification\n",
      "7. text correction\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "1. 生成文本：ChatGPT可以生成与给定主题相关的文章、新闻、博客、推文等等。您可以提供一些关键词或主题，然后ChatGPT将为您生成相关的文本。\n",
    "2. 语言翻译：ChatGPT可以将一种语言的文本翻译成另一种语言。\n",
    "3. 问答系统：ChatGPT可以回答您提出的问题，无论是事实性的问题、主观性的问题还是开放性的问题。\n",
    "4. 对话系统：ChatGPT可以进行对话，您可以与ChatGPT聊天，让它回答您的问题或就某个话题进行讨论。\n",
    "5. 摘要生成：ChatGPT可以从较长的文本中生成摘要，帮助您快速了解文章的主要内容。\n",
    "6. 文本分类：ChatGPT可以将一些给定的文本分类到不同的类别中，例如新闻、体育、科技等等。\n",
    "7. 文本纠错：ChatGPT可以自动纠正文本中的拼写错误和语法错误，提高文本的准确性。 \n",
    "\n",
    "请把上面7段话各自的开头几个词，翻译成英文，并按序号输出。\n",
    "例如，第1段话的开头是\"生成文本\"，那么就输出\"generate text\"\n",
    "\"\"\"\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "print(get_completion(prompt))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2390d73a-13b5-4470-87ee-a4137b65b7b7",
   "metadata": {},
   "source": [
    "    模型通过提供一个示例（即1-shot）已经学会了如何执行任务。\n",
    "对于更困难的任务，我们可以尝试增加演示（例如3-shot、5-shot、10-shot等）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169c7e8-ea36-41b9-bc46-d8f0bb0c3fcb",
   "metadata": {},
   "source": [
    "### Few-shot的限制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f9af03-7da4-4760-a8f4-b0e1ccec5c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答案是True。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "这组数字中的奇数加起来是一个偶数：4、8、9、15、12、2、1。\n",
    "A：答案是False。\n",
    "\n",
    "这组数字中的奇数加起来是一个偶数：17、10、19、4、8、12、24。\n",
    "A：答案是True。\n",
    "\n",
    "这组数字中的奇数加起来是一个偶数：16、11、14、4、8、13、24。\n",
    "A：答案是True。\n",
    "\n",
    "这组数字中的奇数加起来是一个偶数：17、9、10、12、13、4、2。\n",
    "A：答案是False。\n",
    "\n",
    "这组数字中的奇数加起来是一个偶数：15、32、5、13、82、7、1。\n",
    "A：\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 在上面的提示中，我们没有向模型提供任何示例——这就是零样本能力的作用。\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "print(get_completion(prompt))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3df4fe84-ced7-4d4b-aad5-ef8ebca2779e",
   "metadata": {},
   "source": [
    "    这没用。似乎少样本提示不足以获得这种类型的推理问题的可靠响应。上面的示例提供了任务的基本信息。如果仔细观察，我们会发现引入的任务类型涉及几个更多的推理步骤。换句话说，如果我们将问题分解成步骤并向模型演示，这可能会有所帮助。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff47c9-5349-4fac-b021-2e1f53cecf06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 链式思考(思维链COT)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d64e87c5-5b89-4708-8198-2879efa16d41",
   "metadata": {},
   "source": [
    "通过中间推理步骤实现了复杂的推理能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3caf206-6eb6-43ad-ba55-1fdea135345c",
   "metadata": {},
   "source": [
    "<img src=\"./img/思维链.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f8200-3805-47e4-af77-66b4b50ce334",
   "metadata": {},
   "outputs": [],
   "source": [
    "对图片的解释\n",
    "\n",
    "        标准的prompt\n",
    "Q：罗杰有5个网球。他又买了2罐\n",
    "网球。每个罐子有3个网球。有多少\n",
    "他现在有多少个网球?\n",
    "A：答案是11个\n",
    "Q：自助餐厅有23个苹果。如果他们用20\n",
    "做午餐，又买了6个，他们有多少个苹果?\n",
    "A：答案是27个\n",
    "\n",
    "        链式思考的prompt\n",
    "Q：罗杰有5个网球。他又买了2罐\n",
    "网球。每个罐子有3个网球。有多少\n",
    "他现在有多少个网球?\n",
    "A：罗杰一开始有5个球。2罐3个网球，等于6个网球。5 + 6 = 11。答案是11。\n",
    "Q：自助餐厅有23个苹果。如果他们用20\n",
    "做午餐，又买了6个，他们有多少个苹果?\n",
    "A：自助餐厅最初有23个苹果。他们使用20个做午饭。\n",
    "23 - 20 = 3。他们又买了6个苹果，得到3+ 6= 9。答案是9个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db5a4273-0aa1-4268-8f61-1b7b35fd1cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将所有奇数相加（15、5、13、7、1）得到41。答案为False。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。\n",
    "A：将所有奇数相加（9、15、1）得到25。答案为False。\n",
    "这组数中的奇数加起来是偶数：17、10、19、4、8、12、24。\n",
    "A：将所有奇数相加（17、19）得到36。答案为True。\n",
    "这组数中的奇数加起来是偶数：16、11、14、4、8、13、24。\n",
    "A：将所有奇数相加（11、13）得到24。答案为True。\n",
    "这组数中的奇数加起来是偶数：17、9、10、12、13、4、2。\n",
    "A：将所有奇数相加（17、9、13）得到39。答案为False。\n",
    "这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。\n",
    "A：\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "print(get_completion(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b002c-e1ba-4f32-8491-ad931448f520",
   "metadata": {},
   "source": [
    "### 零样本COT提示"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15dabe9a-e633-4292-84d4-3fe1dfdf9e8f",
   "metadata": {},
   "source": [
    "    足够大的语言模型才会出现的新兴能力。提出的一个新想法是零样本CoT(Kojima等人，\n",
    "2022年），它基本上涉及将“让我们逐步思考”添加到原始提示中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4606571-1b4f-4962-a63e-873ad95ad630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 我买了10个苹果。\n",
      "2. 我给了邻居2个苹果和修理工2个苹果，所以剩下10 - 2 - 2 = 6个苹果。\n",
      "3. 我吃了1个苹果，所以还剩下6 - 1 = 5个苹果。\n",
      "4. 然后我又去买了5个苹果，所以现在总共有5 + 5 = 10个苹果。\n",
      "\n",
      "所以，我现在还剩下10个苹果。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# 我去市场买了10个苹果。我给了邻居2个苹果和修理工2个苹果。\n",
    "# 然后我去买了5个苹果并吃了1个。我还剩下多少苹果？\n",
    "# \"\"\"\n",
    "prompt = \"\"\"\n",
    "我去市场买了10个苹果。我给了邻居2个苹果和修理工2个苹果。\n",
    "然后我吃了1个又去买了5个苹果。我还剩下多少苹果？\n",
    "让我们逐步思考。\n",
    "\"\"\"\n",
    "# 在上面的提示中，我们没有向模型提供任何示例——这就是零样本能力的作用。\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2c8df-66a4-4f81-8668-1c3a6bfe4b07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 自我一致性(自洽性)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a9cbf5-10f6-489b-8481-0277769ed071",
   "metadata": {},
   "source": [
    "一种对抗「幻觉」的手段。就像我们做数学题，要多次验算一样。\n",
    "\n",
    "- 同样 prompt 跑多次\n",
    "- 通过投票选出最终结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d8066f-ef81-49f6-bca7-4f82ce01a77c",
   "metadata": {},
   "source": [
    "<img src=\"./img/自洽性.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2899194-ecfc-422c-9a39-1e2a6841815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "prompt2 = \"\"\"\n",
    "现在我70岁了，当我6岁时，我的妹妹是我的年龄的一半。现在我的妹妹多大？请逐步思考\n",
    "\"\"\"\n",
    "prompt= \"\"\"\n",
    "Q：林中有15棵树。林业工人今天将在林中种树。完成后，将有21棵树。林业工人今天种了多少棵树？\n",
    "A：我们从15棵树开始。后来我们有21棵树。差异必须是他们种树的数量。因此，他们必须种了21-15 = 6棵树。答案是6。\n",
    "\n",
    "Q：停车场有3辆汽车，又来了2辆汽车，停车场有多少辆汽车？\n",
    "A：停车场已经有3辆汽车。又来了2辆。现在有3 + 2 = 5辆汽车。答案是5。\n",
    "\n",
    "Q：Leah有32块巧克力，她的姐姐有42块。如果他们吃了35块，他们总共还剩多少块？\n",
    "A：Leah有32块巧克力，Leah的姐姐有42块。这意味着最初有32 + 42 = 74块巧克力。已经吃了35块。因此，他们总共还剩74-35 = 39块巧克力。答案是39。\n",
    "\n",
    "Q：Jason有20个棒棒糖。他给Denny一些棒棒糖。现在Jason只有12个棒棒糖。Jason给Denny多少棒棒糖？\n",
    "A：Jason有20个棒棒糖。因为他现在只有12个，所以他必须把剩下的给Denny。他给Denny的棒棒糖数量必须是20-12 = 8个棒棒糖。答案是8。\n",
    "\n",
    "Q：Shawn有五个玩具。圣诞节，他从他的父母那里得到了两个玩具。他现在有多少个玩具？\n",
    "A：他有5个玩具。他从妈妈那里得到了2个，所以在那之后他有5 + 2 = 7个玩具。然后他从爸爸那里得到了2个，所以总共他有7 + 2 = 9个玩具。答案是9。\n",
    "\n",
    "Q：服务器房间里有9台计算机。从周一到周四，每天都会安装5台计算机。现在服务器房间里有多少台计算机？\n",
    "A：从周一到周四有4天。每天都添加了5台计算机。这意味着总共添加了4 * 5 =\n",
    "20台计算机。一开始有9台计算机，所以现在有9 + 20 = 29台计算机。答案是29。\n",
    "\n",
    "Q：Michael有58个高尔夫球。星期二，他丢失了23个高尔夫球。星期三，他又丢失了2个。星期三结束时他还剩多少个高尔夫球？\n",
    "A：Michael最初有58个球。星期二他丢失了23个，所以在那之后他有58-23 = 35个球。星期三他又丢失了2个，所以现在他有35-2 = 33个球。答案是33。\n",
    "\n",
    "Q：Olivia有23美元。她用每个3美元的价格买了五个百吉饼。她还剩多少钱？\n",
    "A：她用每个3美元的价格买了5个百吉饼。这意味着她花了15美元。她还剩8美元。\n",
    "\n",
    "Q：现在我70岁了，当我6岁时，我的妹妹是我的一半年龄。现在我的妹妹多大？\n",
    "A：\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # 模型输出的随机性，0 表示随机性最小\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "print(get_completion(prompt2))\n",
    "print(get_completion(prompt2))\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10569e2e-58f1-44ed-8a13-e9e464565b62",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 思维树(Tree-of-thought, ToT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec89e2a-ca27-40a8-abf5-fad1b8b4c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "    对于需要探索或预判战略的复杂任务来说，传统或简单的提示技巧是不够的。思维树基于\n",
    "思维链提示进行了总结，引导语言模型探索把思维作为中间步骤来解决通用问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd850876-9290-4bc8-aeff-9b479f5674d1",
   "metadata": {},
   "source": [
    "<img src=\"./img/思维树框架原理.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33ac0f-897a-411c-81e1-c22d9b56535c",
   "metadata": {},
   "source": [
    "<img src=\"./img/算24点游戏思路.png\" width='100%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960731b2-9281-4b54-a7cb-3f78a133d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "思路拆解:\n",
    "    1、思维分解：拆分任务\n",
    "    先进行两个数之间的运算，将计算得到的结果与剩下的某个数再次进行计算，以此类推\n",
    "    2、思维生成：为下一个思维步骤生成n个候选项\n",
    "    由模型提议输出下一步计算方式\n",
    "    3、状态评估：评估候选者解决问题的进展\n",
    "    根据当前的计算方式与剩余数结合能够得到24的概率\n",
    "    4、搜索算法：根据状态，搜索最有希望完成任务的分支\n",
    "    根据得到24的概率，顺序执行分支，抛弃零/低概率分支"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeee1bf-c8dd-469c-8f85-b71e33f1b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 详细见文件 game24.py  game24_prompt.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
